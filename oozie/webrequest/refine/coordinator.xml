<?xml version="1.0" encoding="UTF-8"?>
<coordinator-app xmlns="uri:oozie:coordinator:0.4"
    name="refine_webrequest-${webrequest_source}-coord"
    frequency="${coord:hours(1)}"
    start="${start_time}"
    end="${stop_time}"
    timezone="Universal">

    <parameters>

        <!-- Required properties -->
        <property><name>queue_name</name></property>
        <property><name>name_node</name></property>
        <property><name>job_tracker</name></property>
        <property><name>workflow_file</name></property>
        <property><name>mark_directory_done_workflow_file</name></property>
        <property><name>send_error_email_workflow_file</name></property>

        <property><name>start_time</name></property>
        <property><name>stop_time</name></property>

        <property><name>webrequest_raw_data_directory</name></property>
        <property><name>datasets_raw_file</name></property>
        <property><name>webrequest_data_directory</name></property>
        <property><name>datasets_file</name></property>

        <property><name>hive_site_xml</name></property>
        <property><name>refinery_jar_version</name></property>
        <property><name>artifacts_directory</name></property>
        <property><name>source_table</name></property>
        <property><name>destination_table</name></property>
        <property><name>webrequest_source</name></property>
        <property><name>record_version</name></property>
    </parameters>

    <controls>
        <!--
        By having materialized jobs not timeout, we ease backfilling incidents
        after recoverable hiccups on the dataset producers.
        -->
        <timeout>-1</timeout>

        <!--
        Refining is not too cheap, so we limit
        concurrency.

        Note, that this is per coordinator. So if we run this
        coordinator for say 4 webrequest_sources (see bundle.xml :-)),
        we effectively compute sequence statistics for up to 8
        datasets in parallel.

        Also note, that back-filling is not limited by the
        coordinator's frequency, so back-filling works nicely
        even-though the concurrency is low.
        -->
        <concurrency>2</concurrency>


        <!--
        Since we expect only one incarnation per hourly dataset, the
        default throttle of 12 is way to high, and there is not need
        to keep that many materialized jobs around.

        By resorting to 2, we keep the hdfs checks on the datasets
        low, while still being able to easily feed the concurrency.
        -->
        <throttle>2</throttle>
    </controls>

    <datasets>
        <!--
        Include both raw and refined datasets files.
        $datasets_raw_file will be used as the input events,
        and $datasets_file will be used to determine output
        location in which to add a done-flag.
        -->
        <include>${datasets_raw_file}</include>
        <include>${datasets_file}</include>
    </datasets>

    <input-events>
        <!--
        For now, since we definitly want the refined data to exist, even if
        there is some faulty data (e.g. missing or duplicate), we rely on the
        *_partioned datasets.  This means that data in the refined webrequest
        table may be missing some data.  Be warned!  Check the
        wmf_raw.webrequest_sequence_stats table if you are unsure of the
        quality of this data.
        -->
        <data-in name="raw_input" dataset="webrequest_${webrequest_source}_raw">
            <instance>${coord:current(0)}</instance>
        </data-in>
    </input-events>

    <output-events>
        <data-out name="refined_output" dataset="webrequest_${webrequest_source}">
            <instance>${coord:current(0)}</instance>
        </data-out>
    </output-events>

    <action>
        <workflow>
            <app-path>${workflow_file}</app-path>
            <configuration>
                <property>
                    <name>year</name>
                    <value>${coord:formatTime(coord:nominalTime(), "y")}</value>
                </property>
                <property>
                    <name>month</name>
                    <value>${coord:formatTime(coord:nominalTime(), "M")}</value>
                </property>
                <property>
                    <name>day</name>
                    <value>${coord:formatTime(coord:nominalTime(), "d")}</value>
                </property>
                <property>
                    <name>hour</name>
                    <value>${coord:formatTime(coord:nominalTime(), "H")}</value>
                </property>
                <property>
                    <name>destination_dataset_directory</name>
                    <value>${coord:dataOut('refined_output')}</value>
                </property>
            </configuration>
        </workflow>
    </action>
</coordinator-app>
