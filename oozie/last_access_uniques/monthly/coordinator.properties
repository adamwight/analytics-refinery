# Configures a coordinator to generate monthly uniques using last_access method
# on webrequest table and save a reduces version (uri_host aggregates with
# more than 1000 uniques) in archive folders.
# Any of the following properties are overidable with -D.
# Usage:
#   oozie job -Duser=$USER -Dstart_time=2015-01-05T00:00Z -submit -config oozie/last_access_uniques/monthly/coordinator.properties
#
# NOTE:  The $oozie_directory must be synced to HDFS so that all relevant
#        .xml files exist there when this job is submitted.

name_node                         = hdfs://analytics-hadoop
job_tracker                       = resourcemanager.analytics.eqiad.wmnet:8032
queue_name                        = default

refinery_directory                = ${name_node}/wmf/refinery/current
oozie_directory                   = ${refinery_directory}/oozie
hive_site_xml                     = ${name_node}/user/hive/hive-site.xml

start_time                        = 2015-12-01T00:00Z
# Time to stop running this coordinator.  Year 3000 == never!
stop_time                         = 3000-01-01T00:00Z

# Sub worflows path
mark_directory_done_workflow_file = ${oozie_directory}/util/mark_directory_done/workflow.xml
archive_job_output_workflow_file  = ${oozie_directory}/util/archive_job_output/workflow.xml
send_error_email_workflow_file    = ${oozie_directory}/util/send_error_email/workflow.xml

webrequest_table                  = wmf.webrequest
last_access_uniques_monthly_table   = wmf.last_access_uniques_monthly

# HDFS path to webrequest dataset definition
webrequest_data_directory         = ${name_node}/wmf/data/wmf/webrequest
webrequest_datasets_file          = ${oozie_directory}/webrequest/datasets.xml

# HDFS path to last access uniques dataset definition
last_access_uniques_data_directory = ${name_node}/wmf/data/wmf/last_access_uniques
last_access_uniques_datasets_file = ${oozie_directory}/last_access_uniques/datasets.xml

temporary_directory               = ${name_node}/tmp

# Archive base directory
archive_directory                 = ${name_node}/wmf/data/archive

# Archive directory for webrequest data
uniques_archive_directory         = ${archive_directory}/unique_devices

user                              = hdfs
workflow_file                     = ${oozie_directory}/last_access_uniques/monthly/workflow.xml

# Coordinator app to run.
oozie.use.system.libpath          = true
oozie.action.external.stats.write = true
oozie.coord.application.path      = ${oozie_directory}/last_access_uniques/monthly/coordinator.xml
