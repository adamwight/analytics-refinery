<?xml version="1.0" encoding="UTF-8"?>
<coordinator-app xmlns="uri:oozie:coordinator:0.4"
    name="mediacounts_archive-coord"
    frequency="${coord:days(1)}"
    start="${start_time}"
    end="${stop_time}"
    timezone="Universal">

    <parameters>

        <!-- Required properties. -->
        <property><name>queue_name</name></property>
        <property><name>name_node</name></property>
        <property><name>job_tracker</name></property>
        <property><name>start_time</name></property>
        <property><name>stop_time</name></property>
        <property><name>mediacounts_datasets_file</name></property>
        <property><name>mediacounts_data_directory</name></property>
        <property><name>hive_site_xml</name></property>
        <property><name>workflow_file</name></property>
        <property><name>mediacounts_table</name></property>
        <property><name>mark_directory_done_workflow_file</name></property>
        <property><name>temporary_directory</name></property>
        <property><name>mediacounts_daily_archive_directory</name></property>
        <property><name>archive_job_output_workflow_file</name></property>
    </parameters>

    <controls>
        <!--
        By having materialized jobs not timeout, we ease backfilling incidents
        after recoverable hiccups on the dataset producers.
        -->
        <timeout>-1</timeout>

        <!--
        Since the job only runs daily, even low concurrency allows to catch up
        pretty fast. Hence, we can limit concurrency to 1, as the tsvs typically
        process quite some data.
        -->
        <concurrency>1</concurrency>

        <!--
        In order to keep backfilling after an incident simple, we only start
        throttling materialization after 4 days.
        Due to the low concurrency, and low discrepancy between progressing
        time, and expected availability of datasets, we should typically have
        far less materialized jobs.
        -->
        <throttle>4</throttle>
    </controls>

    <datasets>
        <include>${mediacounts_datasets_file}</include>
    </datasets>

    <input-events>
        <data-in name="mediacounts" dataset="mediacounts_hourly">
            <start-instance>${coord:current(0)}</start-instance>
            <end-instance>${coord:current(23)}</end-instance>
        </data-in>
    </input-events>

    <action>
        <workflow>
            <app-path>${workflow_file}</app-path>
            <configuration>

                <!-- Pass these properties through to the workflow -->
                <property><name>name_node</name><value>${name_node}</value></property>
                <property><name>job_tracker</name><value>${job_tracker}</value></property>
                <property><name>queue_name</name><value>${queue_name}</value></property>

                <property>
                    <name>hive_site_xml</name>
                    <value>${hive_site_xml}</value>
                </property>
                <property>
                    <name>mediacounts_table</name>
                    <value>${mediacounts_table}</value>
                </property>
                <property>
                    <name>year</name>
                    <value>${coord:formatTime(coord:nominalTime(), "yyyy")}</value>
                </property>
                <property>
                    <name>month</name>
                    <value>${coord:formatTime(coord:nominalTime(), "MM")}</value>
                </property>
                <property>
                    <name>day</name>
                    <value>${coord:formatTime(coord:nominalTime(), "dd")}</value>
                </property>
            </configuration>
        </workflow>
    </action>
</coordinator-app>
