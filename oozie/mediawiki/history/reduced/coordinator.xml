<?xml version="1.0" encoding="UTF-8"?>
<coordinator-app xmlns="uri:oozie:coordinator:0.4"
    xmlns:sla="uri:oozie:sla:0.2"
    name="mediawiki-history-reduced-coord"
    frequency="${coord:months(1)}"
    start="${start_time}"
    end="${stop_time}"
    timezone="Universal">

    <parameters>
        <!-- Required properties -->
        <property><name>queue_name</name></property>
        <property><name>name_node</name></property>
        <property><name>job_tracker</name></property>
        <property><name>workflow_file</name></property>
        <property><name>start_time</name></property>
        <property><name>stop_time</name></property>
        <property><name>hive_site_xml</name></property>

        <property><name>datasets_file</name></property>
        <property><name>mw_directory</name></property>
        <property><name>datasets_raw_file</name></property>
        <property><name>mw_raw_directory</name></property>

        <property><name>mw_denormalized_history_table</name></property>
        <property><name>mw_project_namespace_map_table</name></property>
        <property><name>mw_history_reduced_table</name></property>

        <property><name>druid_template_file</name></property>
        <property><name>druid_overlord_url</name></property>
        <property><name>druid_period_start</name></property>

        <property><name>druid_datasource_prefix</name></property>

        <property><name>load_druid_workflow_file</name></property>
        <property><name>mark_directory_done_workflow_file</name></property>
        <property><name>send_error_email_workflow_file</name></property>
    </parameters>

    <controls>
        <!--(timeout is measured in minutes)-->
        <timeout>-1</timeout>

        <!-- Setting low concurrency for resource sharing.
             The job runs pretty fast (~1 minute) and increasing concurrency should not cause any problems-->
        <concurrency>1</concurrency>

        <throttle>2</throttle>

    </controls>

    <datasets>
        <!--
        Include refined and raw datasets files.
        -->
        <include>${datasets_file}</include>
        <include>${datasets_raw_file}</include>
    </datasets>

    <input-events>
        <data-in name="mw_denormalized_history_partitioned" dataset="mw_denormalized_history_partitioned">
            <instance>${coord:current(0)}</instance>
        </data-in>

        <data-in name="mw_project_namespace_map_partitioned" dataset="mw_project_namespace_map_partitioned">
            <instance>${coord:current(0)}</instance>
        </data-in>
    </input-events>

    <output-events>
        <data-out name="mw_history_reduced" dataset="mw_history_reduced">
            <instance>${coord:current(0)}</instance>
        </data-out>
    </output-events>

    <action>
        <workflow>
            <app-path>${workflow_file}</app-path>
            <configuration>
                <property>
                    <name>snapshot</name>
                    <value>${coord:formatTime(coord:nominalTime(), "yyyy")}-${coord:formatTime(coord:nominalTime(), "MM")}</value>
                </property>
                <property>
                    <name>loaded_period</name>
                    <value>${druid_period_start}/${coord:formatTime(coord:dateOffset(coord:nominalTime(), 1, "MONTH"), "yyyy-MM-dd")}</value>
                </property>
                <property>
                    <name>history_reduced_location</name>
                    <value>${coord:dataOut('mw_history_reduced')}</value>
                </property>
            </configuration>
        </workflow>
    </action>
</coordinator-app>