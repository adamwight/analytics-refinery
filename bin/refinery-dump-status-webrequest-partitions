#!/bin/bash

set -e

print_help() {
    cat <<EOF
$0 [ OPTIONS ] [ HOURS_TO_GO_BACK ]

dumps the status of the raw webrequest partitions for the last few hours.

Options:
  --hdfs-mount MOUNT_POINT
                  -- Assume that HDFS is mounted at MOUNT_POINT (needs
                     to be an absolute path) instead of /mnt/hdfs .
  --mark-day-changes
                  -- Adds a hline between days.
  --datasets DATASET1,DATASET2,...
                  -- Select the datasets to output data for.
                     The following datasets are available:
                       legacy_tsvs          -- webrequest (refined tables) (daily)
                       pagecounts-all-sites -- pagecounts-all-sites (hourly)
                       pagecounts-raw       -- pagecounts-raw (hourly)
                       raw_webrequest       -- Raw webrequest (hourly)
                       webrequest           -- webrequest (refined tables) (hourly)
                       all                  -- all of the above

                     By default, only "raw_webrequest" is shown.

  --quiet         -- Only produce output, if there are faulty partitions

HOURS_TO_GO_BACK  -- number of hours to go back in time. (Default: 51)

EOF
}


HOUR_OFFSET_MAX=51
HOUR_OFFSET_MIN=3

HDFS_MOUNT_DIR_ABS=/mnt/hdfs

HAS_FAULTY=
QUIET=
QUIET_BUFFER=

MARK_DAY_CHANGES=no

ALL_DATASETS=()

declare -A DATASET_RECURRENCES
declare -A DATASET_CAPTIONS
declare -A DATASET_HLINES
declare -A DATASET_BLANKS
declare -A DATASET_VISIBILITIES

add_dataset() {
    local DATASET="$1"
    local DATASET_RECURRENCE="$2"
    local DATASET_CAPTION="$3"
    local DATASET_HLINE="$(sed -e 's/[^|]/-/g; s/|/+/g' <<<"$DATASET_CAPTION")"
    local DATASET_BLANK="${DATASET_HLINE//-/ }" ; DATASET_BLANK="${DATASET_BLANK//+/|}"

    ALL_DATASETS=( "${ALL_DATASETS[@]}" "$DATASET" )

    DATASET_RECURRENCES["$DATASET"]="$DATASET_RECURRENCE"
    DATASET_CAPTIONS["$DATASET"]="$DATASET_CAPTION"
    DATASET_HLINES["$DATASET"]="$DATASET_HLINE"
    DATASET_BLANKS["$DATASET"]="$DATASET_BLANK"
    DATASET_VISIBILITIES["$DATASET"]=no
}

add_dataset "legacy_tsvs" "daily" "    5xx    | 5xx-misc  |5xx-mobile | 5xx-text  |5xx-upload |    api    |   edits   | glam_nara |  mobile   |  sampled  |   zero    |"
add_dataset "pagecounts_all_sites" "hourly" " file name date  |  page   | project |"
add_dataset "pagecounts_raw" "hourly" " file name date  |  page   | project |"
add_dataset "raw_webrequest" "hourly" "  bits  |  misc  | mobile |  text  | upload |"
add_dataset "webrequest" "hourly" "  bits  |  misc  | mobile |  text  | upload |"

DATASET_VISIBILITIES["raw_webrequest"]=yes

error() {
    echo "Error" "$@" >&2
    exit 1
}

while [ $# -gt 0 ]
do
    PARAM="$1"
    shift
    case "$PARAM" in
        "--help" | "-h" | "-?" )
            print_help
            exit 1
            ;;
        "--datasets" )
            [[ $# -gt 0 ]] || error "$PARAM expects a further parameter"

            # Resetting previous visibilities
            for INNER_DATASET in "${ALL_DATASETS[@]}"
            do
                DATASET_VISIBILITIES["$INNER_DATASET"]=no
            done

            IFS="," read -a DATASETS_SPLIT <<<"$1"
            for DATASET in "${DATASETS_SPLIT[@]}"
            do
                case "$DATASET" in
                    "all" )
                        for INNER_DATASET in "${ALL_DATASETS[@]}"
                        do
                            DATASET_VISIBILITIES["$INNER_DATASET"]=yes
                        done
                        ;;
                    * )
                        FOUND_DATASET=no
                        for INNER_DATASET in "${ALL_DATASETS[@]}"
                        do
                            if [ "${DATASET//-/_}" = "$INNER_DATASET" ]
                            then
                                DATASET_VISIBILITIES["$INNER_DATASET"]=yes
                                FOUND_DATASET=yes
                            fi
                        done
                        if [ "$FOUND_DATASET" != "yes" ]
                        then
                            error "Unknown dataset '$DATASET '"
                        fi
                        ;;
                esac
            done
            shift
            ;;
        "--hdfs-mount" )
            [[ $# -gt 0 ]] || error "$PARAM expects a further parameter"
            HDFS_MOUNT_DIR_ABS="$1"
            shift
            ;;
        "--mark-day-changes" )
            MARK_DAY_CHANGES=yes
            ;;
        "--quiet" )
            QUIET=yes
            ;;
        * )
            if [ $# -eq 0 ]
            then
                HOUR_OFFSET_MAX="$PARAM"
            else
                error "Too many parameters given"
            fi
            ;;
    esac
done

RAW_WEBREQUEST_DATA_DIR_ABS="$HDFS_MOUNT_DIR_ABS/wmf/data/raw/webrequest"
RAW_WEBREQUEST_STATISTICS_DIR_ABS="$HDFS_MOUNT_DIR_ABS/wmf/data/raw/webrequests_faulty_hosts"
WEBREQUEST_DATA_DIR_ABS="$HDFS_MOUNT_DIR_ABS/wmf/data/wmf/webrequest"
ARCHIVE_DATA_DIR_ABS="$HDFS_MOUNT_DIR_ABS/wmf/data/archive"

log_no_lf() {
    if [ -n "$QUIET" ]
    then
        QUIET_BUFFER="$QUIET_BUFFER$@"
        if [ -n "$HAS_FAULTY" ]
        then
            echo -n "$QUIET_BUFFER"
            QUIET_BUFFER=
        fi
    else
        echo -n "$@"
    fi
}

log_no_lf_centered() {
    local TEXT="$1"
    local AVAILABLE_LEN="$2"

    local BLANK_HELPER="                                                       "
    # Doubling blank helper, so we get a long enough string but stay below 80
    # characters per line.
    BLANK_HELPER="$BLANK_HELPER$BLANK_HELPER"

    local TEXT_LEN="${#TEXT}"

    log_no_lf "${BLANK_HELPER:0:$(( (AVAILABLE_LEN-TEXT_LEN) / 2 ))}"
    log_no_lf "$TEXT"
    log_no_lf "${BLANK_HELPER:0:$(( AVAILABLE_LEN - (AVAILABLE_LEN-TEXT_LEN) / 2 - TEXT_LEN ))}"
}

log() {
    log_no_lf "$@
"
}

hline() {
    local KIND="$1"

    log_no_lf "  "

    # daily datasets first
    if [ "$HAS_VISIBLE_DAILY_DATASETS" = yes ]
    then
        log_no_lf "++---------------++"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "daily" ]
            then
                local DATASET_HLINE="${DATASET_HLINES["$DATASET"]}"
                if [ "$KIND" = "first" ]
                then
                    DATASET_HLINE="${DATASET_HLINE//+-/--}"
                fi
                log_no_lf "${DATASET_HLINE}+"
            fi
        done
    fi

    # Now for the hourly datasets
    if [ "$HAS_VISIBLE_HOURLY_DATASETS" = yes ]
    then
        log_no_lf "++------------------++"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "hourly" ]
            then
                local DATASET_HLINE="${DATASET_HLINES["$DATASET"]}"
                if [ "$KIND" = "first" ]
                then
                    DATASET_HLINE="${DATASET_HLINE//+-/--}"
                fi
                log_no_lf "${DATASET_HLINE}+"
            fi
        done
    fi
    log
}

first_caption_line() {
    local DATASET

    log_no_lf "  "

    # daily datasets first
    if [ "$HAS_VISIBLE_DAILY_DATASETS" = yes ]
    then
        log_no_lf "||               ||"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "daily" ]
            then
                local DATASET_CAPTION="${DATASET_CAPTIONS["$DATASET"]}"
                local DATASET_CAPTION_LEN="${#DATASET_CAPTION}"
                log_no_lf_centered "$DATASET" $((DATASET_CAPTION_LEN-1))
                log_no_lf "||"
            fi
        done
    fi

    # Now for the hourly datasets
    if [ "$HAS_VISIBLE_HOURLY_DATASETS" = yes ]
    then
        log_no_lf "||                  ||"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "hourly" ]
            then
                local DATASET_CAPTION="${DATASET_CAPTIONS["$DATASET"]}"
                local DATASET_CAPTION_LEN="${#DATASET_CAPTION}"
                log_no_lf_centered "$DATASET" $((DATASET_CAPTION_LEN-1))
                log_no_lf "||"
            fi
        done
    fi
    log
}

second_caption_line() {
    local DATASET

    log_no_lf "  "

    # daily datasets first
    if [ "$HAS_VISIBLE_DAILY_DATASETS" = yes ]
    then
        log_no_lf "||      Day      ||"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "daily" ]
            then
                log_no_lf "${DATASET_CAPTIONS["$DATASET"]}"
                log_no_lf "|"
            fi
        done
    fi

    # Now for the hourly datasets
    if [ "$HAS_VISIBLE_HOURLY_DATASETS" = yes ]
    then
        log_no_lf "||       Hour       ||"
        for DATASET in "${ALL_DATASETS[@]}"
        do
            if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "hourly" ]
            then
                log_no_lf "${DATASET_CAPTIONS["$DATASET"]}"
                log_no_lf "|"
            fi
        done
    fi
    log
}

determine_recurrence_visibility() {
    HAS_VISIBLE_DAILY_DATASETS=no
    HAS_VISIBLE_HOURLY_DATASETS=no
    for DATASET in "${ALL_DATASETS[@]}"
    do
        if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" ]
        then
            if [ "${DATASET_RECURRENCES["$DATASET"]}" = "daily" ]
            then
                HAS_VISIBLE_DAILY_DATASETS=yes
            elif [ "${DATASET_RECURRENCES["$DATASET"]}" = "hourly" ]
            then
                HAS_VISIBLE_HOURLY_DATASETS=yes
            else
                error "Unknown recurrence '${DATASET_RECURRENCES["$DATASET"]}' for dataset '$DATASET'"
            fi
        fi
    done
}

dump_dataset_legacy_tsvs() {
    local DATE="$1"

    local SUFFIX=".tsv.log-$(date --utc -d "$DATE 1 hour" +"%Y%m%d").gz"

    local BASE
    for BASE in \
        5xx/5xx \
        5xx-misc/5xx-misc \
        5xx-mobile/5xx-mobile \
        5xx-text/5xx-text \
        5xx-upload/5xx-upload \
        api/api-usage \
        edits/edits \
        glam_nara/glam_nara \
        mobile/mobile-sampled-100 \
        sampled/sampled-1000 \
        zero/zero \

    do
        local STATUS="X"
        local FILE_ABS="$ARCHIVE_DATA_DIR_ABS/webrequest/$BASE$SUFFIX"
        if [ -e "$FILE_ABS" ]
        then
            STATUS="_"
        fi
        log_no_lf "     $STATUS     |"
    done
}

dump_dataset_pagecounts_file() {
    local DATASET="$1"
    local KIND="$2"

    local STATUS="X"

    if [ "$KIND" = page ]
    then
        FILE_ENDING=".gz"
    else
        FILE_ENDING=""
    fi

    FILE_DATE_PART="$(date --utc -d "$DATE 1 hour" +"%Y/%Y-%m/${KIND}counts-%Y%m%d-%H0000")"

    FILE_ABS="$ARCHIVE_DATA_DIR_ABS/${DATASET//_/-}/$FILE_DATE_PART$FILE_ENDING"

    if [ -e "$FILE_ABS" ]
    then
        STATUS="_"
    fi
    log_no_lf "$STATUS"
}

dump_dataset_pagecounts_all_sites() {
    local DATE="$1"
    local DATASET="${2:-pagecounts_all_sites}"

    log_no_lf " $(date --utc -d "$DATE 1 hour" +'%Y%m%d-%H0000') |"
    for KIND in page project
    do
        log_no_lf "    "
        dump_dataset_pagecounts_file "$DATASET" "$KIND"
        log_no_lf "    |"
    done
}

dump_dataset_pagecounts_raw() {
    local DATE="$1"
    dump_dataset_pagecounts_all_sites "$DATE" "pagecounts_raw"
}

dump_dataset_raw_webrequest_partition() {

    local DATE_HDFS_PADDED="$1"
    local SOURCE="$2"
    local STATUS="X"

    local DATE_HDFS_UNPADDED="${DATE_HDFS_PADDED///0//}"

    STATISTICS_FILE_ABS="$RAW_WEBREQUEST_STATISTICS_DIR_ABS/$SOURCE/$DATE_HDFS_UNPADDED/000000_0"
    if [ -e "$STATISTICS_FILE_ABS" -a ! -s "$STATISTICS_FILE_ABS" ]
    then
        STATUS="."
    else
        if [ -e "$RAW_WEBREQUEST_DATA_DIR_ABS/webrequest_$SOURCE/hourly/$DATE_HDFS_PADDED/_SUCCESS" ]
        then
            STATUS="M"
        else
            STATUS="X"
            HAS_FAULTY=yes
        fi
    fi
    log_no_lf "$STATUS"
}

dump_dataset_raw_webrequest() {
    local DATE="$1"

    local DATE_HDFS_PADDED="$(date --utc -d "$DATE" +'%Y/%m/%d/%H')"

    for SOURCE in bits misc mobile text upload
    do
        log_no_lf "    "
        dump_dataset_raw_webrequest_partition "$DATE_HDFS_PADDED" "$SOURCE"
        log_no_lf "   |"
    done
}

dump_dataset_webrequest() {
    local DATE="$1"

    local DATE_DIRS_REL="$(date --utc -d "$DATE" +'year=%Y/month=%m/day=%d/hour=%H')"
    DATE_DIRS_REL="${DATE_DIRS_REL//=0/=}"

    for SOURCE in bits misc mobile text upload
    do
        local STATUS="X"
        SUCCESS_FILE_ABS="$WEBREQUEST_DATA_DIR_ABS/webrequest_source=$SOURCE/$DATE_DIRS_REL/_SUCCESS"
        if [ -e "$SUCCESS_FILE_ABS" ]
        then
            STATUS="_"
        fi
        log_no_lf "    $STATUS   |"
    done
}

determine_recurrence_visibility

hline "first"
first_caption_line
second_caption_line
hline

for HOURS_OFFSET in $(seq $HOUR_OFFSET_MAX -1 $HOUR_OFFSET_MIN )
do
    DATE="$(date --utc -d "$HOURS_OFFSET hours-ago" +'%Y-%m-%d %H')"

    # -- Mark day change if requested
    if [ "$MARK_DAY_CHANGES" = "yes" -a "${DATE: -2}" = "00" -a "$HOURS_OFFSET" != "$HOUR_OFFSET_MAX" ]
    then
        hline
    fi

    # Check if this hour produces output at all. If not, omit it
    # completely. This omitting allows to not get superfluous 23 empty lines,
    # when only daily datasets are visible.
    if [ \( "$HAS_VISIBLE_DAILY_DATASETS" = yes -a \
            \( "${DATE: -2}" = "00" -o "$HOURS_OFFSET" = "$HOUR_OFFSET_MAX" \) \) \
        -o "$HAS_VISIBLE_HOURLY_DATASETS" = yes ]
    then

        log_no_lf "  "

        # daily datasets first
        if [ "$HAS_VISIBLE_DAILY_DATASETS" = yes ]
        then
            if [ "${DATE: -2}" = "00" -o "$HOURS_OFFSET" = "$HOUR_OFFSET_MAX" ]
            then
                log_no_lf "|| ${DATE:0:10}/1D ||"
            else
                log_no_lf "||               ||"
            fi

            for DATASET in "${ALL_DATASETS[@]}"
            do
                if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "daily" ]
                then
                    if [ "${DATE: -2}" = "00"  -o "$HOURS_OFFSET" = "$HOUR_OFFSET_MAX" ]
                    then
                        dump_dataset_$DATASET "$DATE"
                    else
                        log_no_lf "${DATASET_BLANKS["$DATASET"]]}"
                    fi
                    log_no_lf "|"
                fi
            done
        fi

        # Now for the hourly datasets
        if [ "$HAS_VISIBLE_HOURLY_DATASETS" = yes ]
        then
            log_no_lf "|| ${DATE// /T}/1H ||"
            for DATASET in "${ALL_DATASETS[@]}"
            do
                if [ "${DATASET_VISIBILITIES["$DATASET"]}" = "yes" -a "${DATASET_RECURRENCES["$DATASET"]}" = "hourly" ]
                then
                    dump_dataset_$DATASET "$DATE"
                    log_no_lf "|"
                fi
            done
        fi
        log
    fi
done

hline

log "

Statuses:

  . --> Dataset entry passed automated checks
  _ --> Dataset entry is present (does not imply quality guarantees)
  M --> Dataset entry manually marked ok
  X --> Dataset entry is known to not be ok


"
